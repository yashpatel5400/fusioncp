{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.linear_model import Lasso\n",
    "import einops\n",
    "\n",
    "##############################################################################\n",
    "# Placeholder conformal prediction function\n",
    "##############################################################################\n",
    "def conformal_pred_split(X_train, y_train, \n",
    "                         X_cal, y_cal, \n",
    "                         X_test, y_test, alpha=0.05,\n",
    "                         train_fun=None, predict_fun=None, seed=None):\n",
    "    \"\"\"\n",
    "    Mimics R's conformalInference::conformal.pred.split().\n",
    "    This is a placeholder. In practice, you can:\n",
    "    - use MAPIE (https://github.com/scikit-learn-contrib/MAPIE)\n",
    "    - implement split conformal logic manually.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array of shape (n, p)\n",
    "    y_train : array of shape (n,)\n",
    "    X_test  : array of shape (n_test, p)\n",
    "    y_test : array of shape (n_test,)\n",
    "    alpha   : significance level (1 - coverage)\n",
    "    train_fun : callable that trains a model (X, y) -> model\n",
    "    predict_fun : callable that predicts from model (model, X) -> predictions\n",
    "    seed : random seed (if needed)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dict with keys:\n",
    "      'lo': float (lower bound),\n",
    "      'up': float (upper bound)\n",
    "    for each test point. Here we assume n_test=1. If >1, you'd return arrays.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    # Train the model\n",
    "    model = train_fun(X_train, y_train)\n",
    "    preds_cal = predict_fun(model, X_cal)\n",
    "    # Compute residuals (naive approach)\n",
    "    cal_scores = np.abs(y_cal - preds_cal)\n",
    "    \n",
    "    # quantile of absolute residuals\n",
    "    q = np.quantile(cal_scores, 1 - alpha)\n",
    "    \n",
    "    # Predict on test\n",
    "    test_preds  = predict_fun(model, X_test)\n",
    "    test_scores = np.abs(y_test - test_preds)\n",
    "    # If X_test has shape (1, p), preds_test is a single float or shape (1,)\n",
    "    # We'll assume n0=1 as in your R script. If more, adjust accordingly.\n",
    "    if test_preds.shape == ():  # single float\n",
    "        test_preds = np.array([test_preds])\n",
    "    \n",
    "    lo = test_preds - q\n",
    "    up = test_preds + q\n",
    "    \n",
    "    return {'lo': lo, 'up': up, 'scores': cal_scores, 'test_scores': test_scores, 'test_preds': test_preds}\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Lasso \"funs\" (mimicking lasso.funs(...))\n",
    "##############################################################################\n",
    "def lasso_train(X, y, alpha=1.0, fit_intercept=False):\n",
    "    \"\"\"\n",
    "    Train a Lasso model with no standardization (unless you do it outside)\n",
    "    and possibly no intercept (fit_intercept=False).\n",
    "    \"\"\"\n",
    "    model = Lasso(alpha=alpha, fit_intercept=fit_intercept)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def lasso_predict(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "def lasso_funs(lambda_val=1.0, standardize=False, intercept=False):\n",
    "    \"\"\"\n",
    "    Returns a dict with 'train' and 'predict' to mimic R's:\n",
    "      lasso.funs(lambda = lambda_val, standardize = F, intercept = F)\n",
    "    \"\"\"\n",
    "    # In scikit-learn, set fit_intercept=not intercept\n",
    "    # 'standardize' = F means we skip scaling here; user can scale externally if needed\n",
    "    return {\n",
    "        'train': lambda X, y: lasso_train(X, y, alpha=lambda_val, fit_intercept=intercept),\n",
    "        'predict': lasso_predict\n",
    "    }\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Majority Vote & Exchangeable Majority Vote\n",
    "# (Assuming you have them from previous translations; placeholders below.)\n",
    "##############################################################################\n",
    "def majority_vote(M, w, rho=0.5):\n",
    "    \"\"\"\n",
    "    M : 2D array of shape (k, 2)\n",
    "    w : 1D array of shape (k,) for weights\n",
    "    rho: threshold\n",
    "    Returns 2D array of intervals or None\n",
    "    \"\"\"\n",
    "    # (Placeholder logic; adapt your previously translated code)\n",
    "    # unique sorted breakpoints\n",
    "    unique_breaks = np.unique(M.flatten())\n",
    "    unique_breaks.sort()\n",
    "\n",
    "    i = 0\n",
    "    lower = []\n",
    "    upper = []\n",
    "    while i < len(unique_breaks) - 1:\n",
    "        # counts_int-like check\n",
    "        mid = 0.5 * (unique_breaks[i] + unique_breaks[i+1])\n",
    "        # Weighted coverage:\n",
    "        coverage_indicators = [(1 if row[0] <= mid <= row[1] else 0) for row in M]\n",
    "        coverage = np.average(coverage_indicators, weights=w)\n",
    "        cond = (coverage > rho)\n",
    "\n",
    "        if cond:\n",
    "            lower.append(unique_breaks[i])\n",
    "            j = i\n",
    "            while j < len(unique_breaks) - 1 and cond:\n",
    "                j += 1\n",
    "                if j < len(unique_breaks) - 1:\n",
    "                    mid2 = 0.5 * (unique_breaks[j] + unique_breaks[j+1])\n",
    "                    coverage2 = np.average(\n",
    "                        [(1 if row[0] <= mid2 <= row[1] else 0) for row in M],\n",
    "                        weights=w\n",
    "                    )\n",
    "                    cond = (coverage2 > rho)\n",
    "            upper.append(unique_breaks[j])\n",
    "            i = j\n",
    "        i += 1\n",
    "\n",
    "    if len(lower) == 0:\n",
    "        return None\n",
    "    return np.column_stack((lower, upper))\n",
    "\n",
    "def exch_majority_vote(M, tau=0.5):\n",
    "    \"\"\"\n",
    "    Exchangeable majority vote\n",
    "    M: 2D array (k, 2)\n",
    "    tau: threshold\n",
    "    \"\"\"\n",
    "    # (Placeholder logic.)\n",
    "    k = M.shape[0]\n",
    "    if k == 1:\n",
    "        return M\n",
    "    perm_indices = np.random.permutation(k)\n",
    "    permM = M[perm_indices, :]\n",
    "    newM = [None]*k\n",
    "    newM[0] = permM[0,:].reshape(1,2)\n",
    "    for i in range(1, k):\n",
    "        subset = permM[:i+1, :]\n",
    "        w = np.full(i+1, 1/(i+1))\n",
    "        mv = majority_vote(subset, w, rho=tau)\n",
    "        if mv is None:\n",
    "            return None\n",
    "        newM[i] = mv\n",
    "    \n",
    "    # We gather the final intersection across newM\n",
    "    # The R code's logic checks if intervals appear in *all* sets.\n",
    "    # We'll do a simplified approach: take the union in newM and only keep those \n",
    "    # that appear in each list. \n",
    "    # For brevity, return one combined interval or None.\n",
    "\n",
    "    # If you already have a fully working version from earlier translations, use that.\n",
    "    # Here is a minimal approach to avoid an overly long snippet:\n",
    "    if any(x is None for x in newM):\n",
    "        return None\n",
    "    # Flatten all intervals\n",
    "    all_breaks = []\n",
    "    for arr in newM:\n",
    "        all_breaks.extend(arr.flatten())\n",
    "    all_breaks = np.unique(all_breaks)\n",
    "    all_breaks.sort()\n",
    "\n",
    "    if len(all_breaks) < 2:\n",
    "        return None\n",
    "\n",
    "    # We'll just return everything as one big bracket or None\n",
    "    return np.array([[all_breaks[0], all_breaks[-1]]])\n",
    "\n",
    "def exch_rand_majority_vote(M):\n",
    "    \"\"\"\n",
    "    Placeholder for exch_rand_majority_vote(cis),\n",
    "    which is not defined in your snippet.\n",
    "    \n",
    "    We'll guess it does the same as exch_majority_vote but uses \n",
    "    a random threshold 'u' somewhere inside?\n",
    "    \"\"\"\n",
    "    # Minimal stand-in:\n",
    "    # e.g. pick a random threshold in [0.5,1], then call exch_majority_vote\n",
    "    u = np.random.uniform(0.5, 1)\n",
    "    return exch_majority_vote(M, tau=u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation p > n\n",
    "# lasso with different lambda values\n",
    "n  = 200    # number of obs. in the train set\n",
    "n0 = 1_000    # number of obs. in the test set\n",
    "p  = 120    # number of predictors\n",
    "m  = 10     # number of active predictors\n",
    "\n",
    "# beta values\n",
    "# np.random.seed(123)\n",
    "beta_vals = np.concatenate((np.random.normal(loc=0, scale=2, size=m), \n",
    "                            np.zeros(p - m)))\n",
    "\n",
    "# design matrix and outcome\n",
    "X_train = np.random.randn(n, p)\n",
    "y_train = X_train @ beta_vals + np.random.randn(n)\n",
    "\n",
    "X_cal = np.random.randn(n, p)\n",
    "y_cal = X_cal @ beta_vals + np.random.randn(n)\n",
    "\n",
    "# design matrix and outcome (test)\n",
    "X_test = np.random.randn(n0, p)\n",
    "y_test = X_test @ beta_vals + np.random.randn(n0)\n",
    "\n",
    "# lasso for all parameters\n",
    "lambda_vals = np.exp(np.linspace(-4, 1.5, 20))  # seq(-4, 1.5, length=20)\n",
    "k = len(lambda_vals)\n",
    "funs = []\n",
    "for lam in lambda_vals:\n",
    "    funs.append(lasso_funs(lambda_val=lam, standardize=False, intercept=False))\n",
    "\n",
    "# Obtain a conformal prediction interval for each X0 with level (1-alpha/2)\n",
    "alpha = 0.1\n",
    "conf_pred_ints = []\n",
    "for f in funs:\n",
    "    # X0 is shape (1, p), we assume n0=1\n",
    "    out = conformal_pred_split(X_train, y_train, \n",
    "                               X_cal, y_cal,\n",
    "                               X_test, y_test, \n",
    "                               alpha=alpha/2,\n",
    "                               train_fun=f['train'],\n",
    "                               predict_fun=f['predict'],\n",
    "                               seed=123)\n",
    "    conf_pred_ints.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([out['scores'] for out in conf_pred_ints]).T\n",
    "test_scores = np.array([out['test_scores'] for out in conf_pred_ints]).T\n",
    "test_preds = np.array([out['test_preds'] for out in conf_pred_ints]).T\n",
    "ints = np.array([[conf_pred_int[\"lo\"], conf_pred_int[\"up\"]] for conf_pred_int in conf_pred_ints])\n",
    "ints = einops.rearrange(ints, \"k l n -> n k l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj_ints = [exch_majority_vote(int_) for int_ in ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ints = []\n",
    "ys = []\n",
    "\n",
    "for i in range(len(maj_ints)):\n",
    "    if maj_ints[i] is not None:\n",
    "        cleaned_ints.append(maj_ints[i][0])\n",
    "        ys.append(y_test[i])\n",
    "\n",
    "cleaned_ints = np.array(cleaned_ints)\n",
    "ys = np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 200\n",
    "unnorm_dirs = np.abs(np.random.multivariate_normal(np.zeros(k), np.eye(k), size=M))\n",
    "proj_dirs = (unnorm_dirs / np.linalg.norm(unnorm_dirs, axis=1, keepdims=True)).T\n",
    "proj_scores = scores @ proj_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919 -- 0.895\n"
     ]
    }
   ],
   "source": [
    "beta_range = [1-alpha, 1-alpha/k]\n",
    "coverage = 0.0\n",
    "eps = .02\n",
    "\n",
    "while not (1-alpha-eps <= coverage and coverage <= 1-alpha + eps):\n",
    "    beta = (beta_range[0] * .8 + beta_range[1] * .2)\n",
    "    mvcp_proj_quantiles = np.quantile(proj_scores, q=beta, axis=0)\n",
    "    train_covered = einops.reduce(proj_scores < mvcp_proj_quantiles, \"n p -> n\", \"prod\")\n",
    "    coverage = np.sum(train_covered) / len(train_covered)\n",
    "    if coverage < 1-alpha:\n",
    "        beta_range[0] = beta\n",
    "    else:\n",
    "        beta_range[1] = beta\n",
    "    print(f\"{beta} -- {coverage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_region = lambda scores : einops.reduce(scores @ proj_dirs < mvcp_proj_quantiles, \"n p -> n\", \"prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvcp_lens = []\n",
    "exch_maj_vote_lens = []\n",
    "\n",
    "for i in range(len(test_preds)):\n",
    "    if maj_ints[i] is None: # sometimes majority vote fails? skip these for now\n",
    "        continue\n",
    "\n",
    "    test_pred = test_preds[i]\n",
    "    range_ = np.max(test_pred) - np.min(test_pred)\n",
    "    delta  = range_ / 100\n",
    "    candidate_y = np.arange(np.min(test_pred) - range_, np.max(test_pred) + range_, delta)\n",
    "\n",
    "    tiled_pred = einops.repeat(test_pred, \"n -> n s\", s=len(candidate_y))\n",
    "    candidate_scores = np.abs(tiled_pred - candidate_y).T\n",
    "    scores_in_region = in_region(candidate_scores)\n",
    "    \n",
    "    mvcp_len = np.sum(scores_in_region) * delta / range_\n",
    "    exch_maj_vote_len = (maj_ints[i][0][1] - maj_ints[i][0][0]) / range_\n",
    "\n",
    "    mvcp_lens.append(mvcp_len)\n",
    "    exch_maj_vote_lens.append(exch_maj_vote_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvcp_covered = np.mean(in_region(test_scores))\n",
    "exch_maj_covered = np.mean(np.logical_and(cleaned_ints[:,0] <= ys, ys <= cleaned_ints[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867\n",
      "0.9048096192384769\n",
      "1.6735871743486972 (0.9104811418888928)\n",
      "1.8330893218509021 (1.563613101875763)\n"
     ]
    }
   ],
   "source": [
    "print(mvcp_covered)\n",
    "print(exch_maj_covered)\n",
    "\n",
    "print(f\"{np.mean(mvcp_lens)} ({np.std(mvcp_lens)})\")\n",
    "print(f\"{np.mean(exch_maj_vote_lens)} ({np.std(exch_maj_vote_lens)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
